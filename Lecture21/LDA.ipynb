{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9ec0f86",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/ignaciomsarmiento/DSEA/blob/main/Lecture21/LDA.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4ff707",
   "metadata": {},
   "source": [
    "## Modelado de topicos o temas "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83d1048-5fe1-490b-b07e-4cdb9f061faf",
   "metadata": {},
   "source": [
    "### Ejemplo comentarios en we8there"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86b1e25-2435-4e55-9206-8dff42561833",
   "metadata": {},
   "source": [
    "Para estudiar la factorización de texto, pasaremos de la política a los restaurantes. Contamos con 6166 reseñas, con una extensión promedio de 90 palabras por reseña, del ya desaparecido sitio web de viajes `we8there.com`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9ad05d22",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "data(\"we8there\", package = \"textir\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d660a491-bac8-4958-96ac-c506886f72ee",
   "metadata": {},
   "source": [
    "Una característica útil de estas reseñas es que contienen texto y una calificación multidimensional sobre la experiencia general, el ambiente, la comida, el servicio y la relación calidad-precio. Cada aspecto se califica en una escala de cinco puntos, donde 1 indica pésimo y 5 indica excelente. \n",
    "\n",
    "Por ejemplo, un usuario envió una reseña muy positiva para Waffle House #1258 en Bossier City, Luisiana: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92713b92",
   "metadata": {},
   "source": [
    "Waffle House #1258 in Bossier City, Louisiana:\n",
    "\n",
    "*I normally would not revue a Waffle House but this one deserves it. The workers, Amanda, Amy, Cherry, James and J.D. were the most pleasant crew I have seen. While it was only lunch, B.L.T. and chili, it was great. The best thing was the 50’s rock and roll music, not to loud not to soft. This is a rare exception to what you all think a Waffle House is. Keep up the good work.*\n",
    "\n",
    "*Overall: 5, Atmosphere: 5, Food: 5, Service: 5, Value: 5.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1793e023-292a-4781-86ef-94f43d6e42f1",
   "metadata": {},
   "source": [
    "Otro usuario encontró que Sartin's Seafood, no es muy bueno:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4803b572",
   "metadata": {},
   "source": [
    "Sartin’s Seafood in Nassau Bay, Texas,\n",
    "\n",
    "*Had a very rude waitress and the manager wasn’t nice either.*\n",
    "*Overall: 1, Atmosphere: 1, Food: 1, Service: 1, Value: 5.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d5f2bdca",
   "metadata": {
    "scrolled": true,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>even though</dt><dd>1</dd><dt>larg portion</dt><dd>1</dd><dt>mouth water</dt><dd>1</dd><dt>red sauc</dt><dd>1</dd><dt>babi back</dt><dd>1</dd><dt>back rib</dt><dd>1</dd><dt>chocol mouss</dt><dd>1</dd><dt>veri satisfi</dt><dd>1</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[even though] 1\n",
       "\\item[larg portion] 1\n",
       "\\item[mouth water] 1\n",
       "\\item[red sauc] 1\n",
       "\\item[babi back] 1\n",
       "\\item[back rib] 1\n",
       "\\item[chocol mouss] 1\n",
       "\\item[veri satisfi] 1\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "even though\n",
       ":   1larg portion\n",
       ":   1mouth water\n",
       ":   1red sauc\n",
       ":   1babi back\n",
       ":   1back rib\n",
       ":   1chocol mouss\n",
       ":   1veri satisfi\n",
       ":   1\n",
       "\n"
      ],
      "text/plain": [
       " even though larg portion  mouth water     red sauc    babi back     back rib \n",
       "           1            1            1            1            1            1 \n",
       "chocol mouss veri satisfi \n",
       "           1            1 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x <- we8thereCounts\n",
    "x[1,x[1,]!=0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8f4171-cb49-4b46-ab01-c72d98c27bdb",
   "metadata": {},
   "source": [
    "#### Regreso al ejemplo de `we8there`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08b0901-a585-4c93-88c1-26e9057b3325",
   "metadata": {},
   "source": [
    "Vamos a usar `maptpx` de Matt Taddy. El algoritmo esta descipto [\"On Estimation and Selection for Topic Models\"](https://arxiv.org/pdf/1109.4518), e implementa \"Topic Posterior Estimation\" usando inferiencia variacional y nos aproxima una solución a:\n",
    "\n",
    "$$\n",
    "P(W, Z, \\theta, \\varphi; \\alpha, \\beta)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c2cf9839",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "p_load(\"maptpx\") # para modelar topicos\n",
    "\n",
    "x <- as.simple_triplet_matrix(we8thereCounts) #Convierte a formato sparse\n",
    "# Es una estructura sparse  que representa solo los elementos distintos de cero (non-sparse), usando tres vectores:\n",
    "# i: los índices de fila\n",
    "# j: los índices de columna\n",
    "#v: los valores (conteos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c34dc75b",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Estimating on a 6166 document collection.\n",
      "Fitting the 10 topic model.\n",
      "log posterior increase: 4441.8, 461.4, 101.5, 57.4, 51, 19.2, 26.2, 15.3, 15.4, 11.7, 6.7, 12.2, 8, 10.1, 4.8, 5.3, 3.2, 6.6, 2.8, 7, 3.6, 3.9, 6.7, 5.5, 8.6, 5, 11, 10.3, 12, 7.9, 12.1, 9, 8.8, 13.9, 8.6, 7.3, 6.1, 4.9, 4.3, 12, 11.1, 8.7, 3.2, 2.8, 5.1, 1.9, 2.6, 2.4, 4.9, 2.9, 1.5, 2.5, 4.7, 1.7, 0.9, 1.4, 0.7, 2.5, 2.2, 1.7, 1, 1.3, 1.5, 2, 0.8, 1.7, 0.5, 0.2, 0.5, 0.6, 0.9, 3.9, 0.5, 0.6, 0.4, 0.2, 0.8, 0.2, 1.4, 0.3, 0.5, 0.6, done.\n"
     ]
    }
   ],
   "source": [
    "tpc <- topics(x,K=10) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f14159f-2ee1-4a20-97e7-e1313d9f412c",
   "metadata": {},
   "source": [
    "Podemos comparar multiples K, para determinar el número óptimo de tópicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "09545b33",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Estimating on a 6166 document collection.\n",
      "Fit and Bayes Factor Estimation for K = 5 ... 25\n",
      "log posterior increase: 2853.9, 327.1, 85.3, 36.7, 25.9, 19.9, 13.8, 11.6, 9.6, 11.4, 20.3, 7.1, 3.9, 8.3, 4, 5.9, 2.4, 3.8, 4.8, 5.3, 3.8, 4.5, 4, 3.8, 2.1, 2, 4.8, 4.5, 2.5, 4.3, 7, 4.9, 9.3, 2.9, 9.9, 3.8, 6.2, 7.3, 3.8, 6, 7.9, 7.4, 7.2, 4, 5.6, 8, 14.3, 11.5, 17.6, 14.8, 14.1, 14.4, 9.5, 7.1, 5.4, 5.8, 2.4, 2.5, 1.5, 1.1, 1.9, 2.9, 2.8, 3.1, 1, 0.8, 0.4, 1.9, 1.3, 0.8, 0.8, 1.1, 1, 2.2, 1, 0.7, 0.4, 0.4, 0.4, 2, 0.4, 0.7, 0.2, 0.3, 2.2, 0.4, 0.3, 0.1, 0.2, done.\n",
      "log BF( 5 ) = 79521.94\n",
      "log posterior increase: 4626.7, 197.4, 53, 24.9, 19, 9.3, 7.4, 4.6, 5.2, 3.4, 2.3, 1.7, 0.8, 0.6, 0.9, 0.5, 0.8, 2.6, 2.7, 1, 0.5, 0.3, 1.1, 0.5, 0.6, 0.7, 1.3, 0.2, done.\n",
      "log BF( 10 ) = 87157.28\n",
      "log posterior increase: 3445, 170.2, 49.8, 23.6, 14.1, 31.4, 16.2, 4.8, 6.6, 5.5, 1.9, 5.9, 4, 2.5, 1.8, 2.1, 1.3, 0.7, 3.6, 1.1, 1.3, 0.7, 0.9, 1.1, 1.8, 1.3, 0.8, 1, 0.3, 0.7, 0.4, 1.2, 0.7, 0.8, 0.1, done.\n",
      "log BF( 15 ) = 3334.33\n",
      "log posterior increase: 2327.1, 139.8, 39.5, 16.7, 20.1, 5.3, 4.5, 3, 3.4, 2.9, 4.4, 1.8, 1, 0.7, 0.6, 0.6, 3.6, 0.4, 0.3, 0.3, 0.3, 0.8, 2.3, 1.4, 0.1, 0.2, done.\n",
      "log BF( 20 ) = -66254.44\n"
     ]
    }
   ],
   "source": [
    "tpcs <- topics(x,K=5*(1:5), verb=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a3038c-db8f-4e6d-b439-812a86d26c18",
   "metadata": {},
   "source": [
    "El Bayes Factor aqui se refiere a \n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    " \\exp\\left(- \\text{BIC}\\right)  \\approx P(W, Z, \\theta, \\varphi; \\alpha, \\beta)\n",
    "$$\n",
    "\n",
    "entonces:\n",
    "\n",
    "$$\n",
    "\\log P(W, Z, \\theta, \\varphi; \\alpha, \\beta) \\approx - \\text{BIC}\n",
    "$$\n",
    "\n",
    "Entonces si nosotros buscabamos minimizar el BIC, vamos a quere maximizar el BF.\n",
    "\n",
    "*Aside*: el BIC aqui va a ser\n",
    "\n",
    "$$\n",
    "\\text{BIC} =  \\log \\hat{L} - \\frac{1}{2} \\left[ K(V - 1) + D(K - 1) \\right] \\cdot \\log(n)\n",
    "$$\n",
    "\n",
    "* $\\hat{L}$: log-likelihood del modelo (`mod$loglik` en `maptpx`)\n",
    "* $V$: número de palabras en el vocabulario\n",
    "* $D$: número de documentos\n",
    "* $K$: número de tópicos\n",
    "* $n$: número total de palabras en el corpus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd7f3da-15a3-4aa0-bb6b-2047f9c3c9ed",
   "metadata": {},
   "source": [
    "La maximización del Bayes Factor en `maptpx` encuentra un valor de $K$ que funciona bien para una variedad de tareas posteriores, aunque a veces tiende a seleccionar un $K$ **más pequeño del que nos gustaría** para fines de *storytelling*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f502508e-1241-4ac7-9c99-3d5e3513659b",
   "metadata": {},
   "source": [
    "**Como se relaciona con otras medidas?**\n",
    "\n",
    "##### Perplexity\n",
    "\n",
    "La **perplejidad** (perplexity) es una transformación de la log-verosimilitud, usada como medida de **cuán bien el modelo predice nuevas palabras**.\n",
    "\n",
    "Se define como:\n",
    "\n",
    "$$\n",
    "\\text{Perplexity}(\\mathbf{w}) = \\exp\\left( - \\frac{1}{N} \\log P(W, Z, \\theta, \\varphi; \\alpha, \\beta) \\right)\n",
    "$$\n",
    "\n",
    "* Cuanto **más baja**, **mejor el modelo predice**.\n",
    "* Se puede calcular sobre un conjunto de test → mide **poder predictivo**.\n",
    "\n",
    "##### Coherence\n",
    "* **Coherencia** mide **cuán interpretables y temáticamente consistentes** son los tópicos. Lo hace calculado qué tan frecuentemente **las palabras más probables de un tópico coocurren en los mismos documentos**. Si las palabras clave de un tópico tienden a aparecer juntas, decimos que el tópico es **coherente**.\n",
    "\n",
    "* No depende de la log-verosimilitud ni del Bayes factor.\n",
    "* Se calcula a partir de:\n",
    "\n",
    "  * las palabras más frecuentes de cada tópico,\n",
    "  * y su coocurrencia en los documentos.\n",
    "\n",
    "* Mide si los tópicos \"tienen sentido\" según cómo las palabras aparecen juntas en los textos.\n",
    "\n",
    "Formula: \n",
    "* Tópico $k$ tiene palabras $w_1, w_2, \\dots, w_M$\n",
    "* Cada $w_i$ es una palabra del vocabulario (por ejemplo, las n más probables según $\\phi_k$)\n",
    "\n",
    "Entonces:\n",
    "\n",
    "$$\n",
    "\\text{Coherencia}(k) = \\sum_{i < j} \\log \\left( \\frac{D(w_i, w_j) + \\epsilon}{D(w_j)} \\right)\n",
    "$$\n",
    "\n",
    "donde:\n",
    "\n",
    "* $D(w_j)$: número de documentos que contienen la palabra $w_j$\n",
    "* $D(w_i, w_j)$: número de documentos que contienen ambas $w_i$ y $w_j$\n",
    "* $\\epsilon$: pequeño valor para evitar log(0), usualmente 1\n",
    "\n",
    "*Ejemplo*: \n",
    "Supongamos que un tópico tiene como palabras más probables:\n",
    "\n",
    "$$\n",
    "\\text{\"hospital\", \"médico\", \"enfermera\", \"paciente\"}\n",
    "$$\n",
    "\n",
    "Estas palabras suelen aparecer juntas en los documentos → el tópico es coherente.\n",
    "\n",
    "Ahora imagina:\n",
    "\n",
    "$$\n",
    "\\text{\"hospital\", \"perro\", \"impuestos\", \"fútbol\"}\n",
    "$$\n",
    "\n",
    "Estas palabras no aparecen juntas normalmente → el tópico es incoherente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38a56d4-02a0-4f9b-82e1-4940d4f29484",
   "metadata": {},
   "source": [
    "##### Interpretación\n",
    "\n",
    "La interpretación de los tópicos se realiza de manera similar a como se hace con PCA\n",
    "\n",
    "Podemos comenzar observando las \"palabras principales\" de cada tópico.\n",
    "\n",
    "Pero para que esto sea útil, hay que tener cuidado con el criterio que se usa para ordenar las palabras consideradas \"principales\".\n",
    "\n",
    "Si las ordenás por la **probabilidad de palabra en el tópico** ($\\phi_{kj}$), terminarás con palabras que son frecuentes en el tópico $k$, pero que también pueden ser comunes en otros tópicos —esto pasa especialmente si eliminaste solo un pequeño conjunto de *stopwords*.\n",
    "\n",
    "En su lugar, la función `summary()` de `maptpx` ordena las palabras según el **lift**:\n",
    "\n",
    "$$\n",
    "\\text{lift}_{kj} = \\frac{\\phi_{kj}}{\\bar{x}_j} = \\frac{\\text{especificidad en el tópico}}{\\text{frecuencia global}}\n",
    "$$\n",
    "\n",
    "donde $\\bar{x}_j$ es la frecuencia promedio de la palabra $j$ en el corpus (es decir, su proporción promedio entre los documentos).\n",
    "\n",
    "Este **lift** será alto para palabras que son **mucho más frecuentes en el tópico $k$** de lo que son en el lenguaje general del corpus.\n",
    "Por eso, usar lift ayuda a resaltar palabras **más exclusivas o distintivas del tópico**, y no simplemente comunes en todo el corpus.\n",
    "\n",
    "\n",
    "* Si $\\text{lift}_{kj} > 1$: la palabra es **más característica** del tópico que del corpus.\n",
    "* Si $\\text{lift}_{kj} \\ll 1$: es una palabra común (no distintiva).\n",
    "\n",
    "El lift evita que en los tópicos aparezcan como “principales” palabras genéricas, que aunque sean frecuentes en todos los documentos, **no ayudan a interpretar el tópico en cuestión**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966bb451",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "summary(tpcs, n=10) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f3e2af-a3ff-404e-9171-e9b0b8668728",
   "metadata": {},
   "source": [
    "El primer tópico contiene retroalimentación positiva, y por eso tiene la misma interpretación que el primer componente principal (PC1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9866b7f9",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "rownames(tpcs$theta)[order(tpcs$theta[,1], decreasing=TRUE)[1:10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52df062c-0236-442a-87a6-a1dcd03b065f",
   "metadata": {},
   "source": [
    "Pero los otros tópicos parecen distintos y más interpretables que los factores obtenidos mediante PCA.\n",
    "Por ejemplo:\n",
    "\n",
    "El tópico 2 trata sobre tener que esperar,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f4f4a1",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "rownames(tpcs$theta)[order(tpcs$theta[,2], decreasing=TRUE)[1:10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5ddc0b-5e76-40fa-817b-20f7ade177b5",
   "metadata": {},
   "source": [
    "El tópico 3 incluye reseñas positivas de clientes frecuentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10faced8-b35c-4ad6-a6f5-1efa83d25cce",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "rownames(tpcs$theta)[order(tpcs$theta[,3], decreasing=TRUE)[1:10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f4e1b6-7163-45e9-851e-8e295ded91cd",
   "metadata": {},
   "source": [
    "Podemos comparar los **scores de tópicos** (los $\\theta$) con las **calificaciones de las reseñas**.\n",
    "\n",
    "Veamos la **calificación general** en función de los **scores de los documentos** en el primer topico\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7581e453",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "boxplot(tpcs$omega[,1] ~ we8thereRatings$Overall, col=\"gold\", xlab=\"overall rating\", ylab=\"topic 1 score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c4f373-bdcc-4702-a512-e752dff918c8",
   "metadata": {},
   "source": [
    "Hay claramente una **relación positiva entre el tópico 1 y la calificación general**  que lo que se observaba usando el **primer componente principal (PC1)**. (HW)\n",
    "\n",
    "y en el segundo vemos algo parecido:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba2c285",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "boxplot(tpcs$omega[,2] ~ we8thereRatings$Overall, col=\"pink\", xlab=\"overall rating\", ylab=\"topic 2 score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bfaee4-b456-4d2e-80b5-4cf52d8c563f",
   "metadata": {},
   "source": [
    "Estas relaciones sugieren una estrategia de **regresión sobre tópicos** para predecir la **calificación de una reseña** a partir de su **contenido textual**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f7af4b-19be-42f0-9570-b76249182219",
   "metadata": {},
   "source": [
    "#### Prediciendo los ratings en `we8there`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868c2232",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "stars <- we8thereRatings[,\"Overall\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b19f51d",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "Xtopics<-as(tpcs$omega, \"dMatrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518a3230-2efa-4eed-af50-a2ef67b08aaa",
   "metadata": {},
   "source": [
    "#### Lasso temas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a90c427",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "p_load(\"gamlr\")\n",
    "regtopics.cv <- cv.gamlr(tpcs$omega, stars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2e7453-9afc-44d5-b552-bea4100ee6e9",
   "metadata": {},
   "source": [
    "#### Lasso palabras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d73b26d",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "regwords.cv <- cv.gamlr(we8thereCounts, stars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba61f519-b559-42bf-b18b-455c592c73bb",
   "metadata": {},
   "source": [
    "Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25577b5f",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "par(mfrow=c(1,2), mai=c(.3,.6,.7,.1), omi=c(.5,.2,0,0))\n",
    "plot(regtopics.cv, ylim=c(1,2), xlab=\"\", ylab=\"\")\n",
    "mtext(\"topic regression\", font=2, line=2)\n",
    "plot(regwords.cv, ylim=c(1,2), xlab=\"\", ylab=\"\")\n",
    "mtext(\"token regression\", font=2, line=2)\n",
    "mtext(side=2, \"mean squared error\", outer=TRUE, line=0)\n",
    "mtext(side=1, \"log lamba\", outer=TRUE, line=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
